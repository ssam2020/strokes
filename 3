import sys
import cv2
import numpy as np
import os
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                            QHBoxLayout, QPushButton, QFileDialog, QLabel,
                            QSlider, QStyle, QMessageBox, QSpinBox, QCheckBox, QColorDialog)
from PyQt5.QtCore import Qt, QTimer, QRect, QPoint
from PyQt5.QtGui import QPixmap, QImage, QPainter, QPen, QColor
from PIL import Image

class VideoConverter(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Video to PNG Converter")
        self.setGeometry(100, 100, 800, 600)
        
        # Video state
        self.cap = None
        self.playing = False
        self.start_frame = 0
        self.end_frame = 0
        self.current_frame = 0
        self.crop_rect = QRect()
        self.drawing = False
        self.crop_visible = True
        
        # Initialize base color
        self.base_color = (255, 255, 255)  # BGR format for OpenCV
        
        # Main UI components
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)

        # File selection row
        file_layout = QHBoxLayout()
        self.btn_open = QPushButton("Open Video")
        self.btn_png_input = QPushButton("Select PNG Sequence")
        file_layout.addWidget(self.btn_open)
        file_layout.addWidget(self.btn_png_input)
        main_layout.addLayout(file_layout)

        # Video display (takes majority of space)
        self.video_label = QLabel()
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.mousePressEvent = self.mouse_press
        self.video_label.mouseMoveEvent = self.mouse_move
        self.video_label.mouseReleaseEvent = self.mouse_release
        main_layout.addWidget(self.video_label, stretch=3)

        # Create buttons before using them
        self.btn_convert = QPushButton("Convert to PNG")
        self.btn_process = QPushButton("Process Sequence")

        # Action buttons row
        action_layout = QHBoxLayout()
        
        # Create ultra-compact color controls
        color_widget = QWidget()
        color_widget.setFixedWidth(40)  # Force narrow width
        color_layout = QHBoxLayout(color_widget)
        color_layout.setContentsMargins(0, 0, 0, 0)
        color_layout.setSpacing(0)
        
        self.base_color_check = QCheckBox()
        self.base_color_check.setFixedSize(16, 16)  # Smaller checkbox
        self.base_color_check.setStyleSheet("""
            QCheckBox::indicator {
                width: 14px;
                height: 14px;
                margin: 0;
            }
        """)
        
        self.base_color_btn = QPushButton()
        self.base_color_btn.setFixedSize(20, 16)  # Match checkbox height
        self.base_color_btn.setStyleSheet("""
            QPushButton {
                background-color: white;
                margin: 0;
                padding: 0;
                border: 1px solid #888;
            }
            QPushButton:hover {
                border: 2px solid #444;
            }
        """)
        self.base_color_btn.clicked.connect(self.choose_base_color)

        color_layout.addWidget(self.base_color_check)
        color_layout.addWidget(self.base_color_btn)
        
        # Add to main action layout
        action_layout.addWidget(color_widget)
        action_layout.addWidget(self.btn_convert)
        action_layout.addWidget(self.btn_process)
        
        # Tight layout settings
        action_layout.setSpacing(2)
        action_layout.setContentsMargins(0, 0, 0, 0)
        
        main_layout.addLayout(action_layout)

        # Threshold controls
        threshold_layout = QHBoxLayout()
        self.threshold_label = QLabel("Difference Threshold (1-100):")
        self.threshold_input = QSpinBox()
        self.threshold_input.setRange(1, 100)
        self.threshold_input.setValue(1)
        threshold_layout.addWidget(self.threshold_label)
        threshold_layout.addWidget(self.threshold_input)
        main_layout.addLayout(threshold_layout)

        # Playback controls
        control_layout = QHBoxLayout()
        self.btn_play = QPushButton()
        self.btn_play.setIcon(self.style().standardIcon(QStyle.SP_MediaPlay))
        self.btn_play.clicked.connect(self.toggle_playback)
        control_layout.addWidget(self.btn_play)
        
        self.slider = QSlider(Qt.Horizontal)
        self.slider.sliderMoved.connect(self.set_position)
        control_layout.addWidget(self.slider)
        main_layout.addLayout(control_layout)
        
        # Range selection
        range_layout = QHBoxLayout()
        self.start_slider = QSlider(Qt.Horizontal)
        self.start_slider.setStyleSheet("QSlider::handle:horizontal { background: red; }")
        self.start_slider.sliderMoved.connect(self.update_start)
        self.start_slider.sliderReleased.connect(self.show_current_range)
        range_layout.addWidget(self.start_slider)
        
        self.end_slider = QSlider(Qt.Horizontal)
        self.end_slider.setStyleSheet("QSlider::handle:horizontal { background: blue; }")
        self.end_slider.sliderMoved.connect(self.update_end)
        self.end_slider.sliderReleased.connect(self.show_current_range)
        range_layout.addWidget(self.end_slider)
        main_layout.addLayout(range_layout)

        # Single connection for each button
        self.btn_open.clicked.connect(self.open_file)
        self.btn_png_input.clicked.connect(self.select_png_sequence)
        self.btn_convert.clicked.connect(self.convert_video)
        self.btn_process.clicked.connect(self.process_png_sequence)
        
        # Timer for video playback
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_frame)
        
        # Color button setup
        self.base_color_btn.setStyleSheet("background-color: white")
        
    def select_png_sequence(self):
        self.png_folder = QFileDialog.getExistingDirectory(self, "Select PNG Sequence")
        
    def process_png_sequence(self):
        if not hasattr(self, 'png_folder'):
            QMessageBox.critical(self, "Error", "No PNG folder selected")
            return
            
        output_folder = os.path.join(self.png_folder, "processed")
        os.makedirs(output_folder, exist_ok=True)
        
        files = sorted([f for f in os.listdir(self.png_folder) if f.endswith(".png")])
        prev_output = None
        threshold = self.threshold_input.value()

        # Get reference dimensions from first image
        first_image = cv2.imread(os.path.join(self.png_folder, files[0]))
        if first_image is None:
            QMessageBox.critical(self, "Error", "Failed to read first image")
            return
            
        ref_height, ref_width = first_image.shape[:2]
        transparent_base = np.zeros((ref_height, ref_width, 4), dtype=np.uint8)

        for i, filename in enumerate(files):
            current_path = os.path.join(self.png_folder, filename)
            current_img = cv2.imread(current_path, cv2.IMREAD_COLOR)
            
            # Validate image dimensions
            if current_img is None:
                QMessageBox.critical(self, "Error", f"Failed to read {filename}")
                return
                
            h, w = current_img.shape[:2]
            if h != ref_height or w != ref_width:
                QMessageBox.critical(self, "Error", 
                    f"Image {filename} has different size ({w}x{h}) than first image ({ref_width}x{ref_height})")
                return
            
            if i == 0:
                # Save first frame as fully transparent
                output_path = os.path.join(output_folder, f"processed_{i:04d}.png")
                cv2.imwrite(output_path, transparent_base)
                prev_output = transparent_base
                continue
                
            # Get previous frame
            prev_img = cv2.imread(os.path.join(self.png_folder, files[i-1]), cv2.IMREAD_COLOR)
            
            # Calculate difference with previous frame
            difference = cv2.absdiff(current_img, prev_img)
            gray_diff = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY).astype(np.float32)
            
            # Normalize and apply exponential scaling
            max_diff = np.max(gray_diff)
            if max_diff > 0:
                normalized_diff = gray_diff / max_diff
                # Scale to reach 1.0 at 75% difference
                scaled_diff = np.minimum(normalized_diff * (4/3), 1.0)  # 1/0.75 = 1.333...
                # Calculate exact exponent for 5% alpha at 50% difference
                exponent = np.log(0.05) / np.log(2/3)  # â‰ˆ7.386
                alpha_mask = (np.power(scaled_diff, exponent) * 255).astype(np.uint8)
            else:
                alpha_mask = np.zeros_like(gray_diff, dtype=np.uint8)
            
            # Create BGRA with alpha mask
            current_bgra = cv2.cvtColor(current_img, cv2.COLOR_BGR2BGRA)
            current_bgra[:, :, 3] = alpha_mask
            
            # Composite with proper alpha premultiplication
            if prev_output is not None:
                # Convert to float for accurate calculations
                bg = prev_output.astype(np.float32) / 255.0
                fg = current_bgra.astype(np.float32) / 255.0
                
                # Calculate combined alpha (additive but clamped)
                combined_alpha = np.minimum(bg[:,:,3] + fg[:,:,3], 1.0)
                
                # Blend colors using weighted average based on new alpha contribution
                # Where: new_color = (fg_color * fg_alpha + bg_color * bg_alpha * (1 - fg_alpha)) / combined_alpha
                # But simplified for additive behavior with latest color priority:
                combined_rgb = fg[:,:,:3]  # Use latest color directly
                
                # Convert back to 8-bit with premultiplied alpha
                premultiplied = np.dstack((
                    (combined_rgb * combined_alpha[..., np.newaxis]) * 255,
                    combined_alpha * 255
                )).astype(np.uint8)
                
                prev_output = premultiplied
            else:
                prev_output = current_bgra
                
            # Save processed image
            output_path = os.path.join(output_folder, f"processed_{i:04d}.png")
            cv2.imwrite(output_path, prev_output)
            
            # Update progress
            if i % 10 == 0:
                QApplication.processEvents()

        QMessageBox.information(self, "Success", f"Processed {len(files)} images")

    def open_file(self):
        path, _ = QFileDialog.getOpenFileName(self, "Open Video", "", "MP4 Files (*.mp4)")
        if path:
            self.cap = cv2.VideoCapture(path)
            if not self.cap.isOpened():
                QMessageBox.critical(self, "Error", "Could not open video file")
                return
                
            # Initialize crop rectangle to full video size
            self.original_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            self.original_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            self.crop_rect = QRect(0, 0, self.original_width, self.original_height)
            
            self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            self.slider.setMaximum(self.total_frames)
            self.start_slider.setMaximum(self.total_frames)
            self.end_slider.setMaximum(self.total_frames)
            self.end_slider.setValue(self.total_frames)
            self.start_frame = 0
            self.end_frame = self.total_frames
            self.show_frame(0)
            
    def show_frame(self, frame_num):
        if self.cap:
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
            ret, frame = self.cap.read()
            if ret:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                h, w, ch = frame.shape
                bytes_per_line = ch * w
                q_img = QImage(frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
                pixmap = QPixmap.fromImage(q_img)
                
                # Draw crop rectangle with boundary checks
                if not self.crop_rect.isNull() and self.crop_visible:
                    # Keep rectangle within video bounds
                    self.crop_rect = self.crop_rect.intersected(QRect(0, 0, w, h))
                    
                    painter = QPainter(pixmap)
                    painter.setPen(QPen(Qt.red, 2, Qt.DashLine))
                    
                    # Convert coordinates for scaled display
                    scale_x = pixmap.width() / w
                    scale_y = pixmap.height() / h
                    display_rect = QRect(
                        int(self.crop_rect.x() * scale_x),
                        int(self.crop_rect.y() * scale_y),
                        int(self.crop_rect.width() * scale_x),
                        int(self.crop_rect.height() * scale_y)
                    )
                    painter.drawRect(display_rect)
                    painter.end()
                
                self.video_label.setPixmap(pixmap.scaled(self.video_label.size(), 
                                                       Qt.KeepAspectRatio))
                
    def toggle_playback(self):
        self.playing = not self.playing
        self.btn_play.setIcon(self.style().standardIcon(
            QStyle.SP_MediaPlay if not self.playing else QStyle.SP_MediaPause))
        if self.playing:
            self.timer.start(30)
        else:
            self.timer.stop()
            
    def update_frame(self):
        if self.current_frame < self.end_frame:
            self.current_frame += 1
            self.slider.setValue(self.current_frame)
            self.show_frame(self.current_frame)
        else:
            self.toggle_playback()
            
    def set_position(self, position):
        self.current_frame = position
        self.show_frame(position)
        
    def update_start(self, position):
        self.start_frame = min(position, self.end_frame-1)
        self.start_slider.setValue(self.start_frame)
        self.show_frame(self.start_frame)

    def update_end(self, position):
        self.end_frame = max(position, self.start_frame+1)
        self.end_slider.setValue(self.end_frame)
        self.show_frame(self.end_frame)

    def show_current_range(self):
        self.show_frame(self.current_frame)

    def mouse_press(self, event):
        if self.cap:
            # Convert mouse position to original video coordinates
            pixmap = self.video_label.pixmap()
            scale_x = self.original_width / pixmap.width()
            scale_y = self.original_height / pixmap.height()
            
            pos = event.pos()
            x = int((pos.x() - (self.video_label.width() - pixmap.width())/2) * scale_x)
            y = int((pos.y() - (self.video_label.height() - pixmap.height())/2) * scale_y)
            
            # Keep within video bounds
            x = max(0, min(x, self.original_width))
            y = max(0, min(y, self.original_height))
            
            self.drawing = True
            self.crop_rect.setTopLeft(QPoint(x, y))
            self.crop_rect.setBottomRight(QPoint(x, y))

    def mouse_move(self, event):
        if self.drawing and self.cap:
            # Same coordinate conversion as mouse_press
            pixmap = self.video_label.pixmap()
            scale_x = self.original_width / pixmap.width()
            scale_y = self.original_height / pixmap.height()
            
            pos = event.pos()
            x = int((pos.x() - (self.video_label.width() - pixmap.width())/2) * scale_x)
            y = int((pos.y() - (self.video_label.height() - pixmap.height())/2) * scale_y)
            
            # Keep within video bounds
            x = max(0, min(x, self.original_width))
            y = max(0, min(y, self.original_height))
            
            self.crop_rect.setBottomRight(QPoint(x, y))
            self.show_frame(self.current_frame)

    def mouse_release(self, event):
        self.drawing = False
        self.crop_rect = self.crop_rect.normalized()
        
    def choose_base_color(self):
        color = QColorDialog.getColor()
        if color.isValid():
            self.base_color = (color.blue(), color.green(), color.red())  # BGR for OpenCV
            self.base_color_btn.setStyleSheet(f"background-color: {color.name()}")

    def convert_video(self):
        if not self.cap:
            QMessageBox.critical(self, "Error", "No video loaded")
            return
            
        # Get threshold from input
        threshold = self.threshold_input.value()
        
        # Get conversion parameters
        output_folder = "output_frames"
        
        # Validate crop rectangle
        if self.crop_rect.width() < 10 or self.crop_rect.height() < 10:
            QMessageBox.critical(self, "Error", "Invalid crop area")
            return

        try:
            # Set up video capture with time range
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.start_frame)
            prev_frame = None
            frame_count = 0
            saved_count = 0
            
            # Create output directory
            os.makedirs(output_folder, exist_ok=True)

            # Get crop dimensions
            x = self.crop_rect.x()
            y = self.crop_rect.y()
            w = self.crop_rect.width()
            h = self.crop_rect.height()

            # Create initial color base if requested
            if self.base_color_check.isChecked():
                # Use CROPPED dimensions for color base
                color_base = np.full((h, w, 3), self.base_color, dtype=np.uint8)
                color_path = os.path.join(output_folder, f"frame_{saved_count:04d}.png")
                cv2.imwrite(color_path, color_base)
                saved_count += 1

            # Conversion loop
            while self.cap.isOpened() and frame_count <= (self.end_frame - self.start_frame):
                ret, frame = self.cap.read()
                if not ret:
                    break

                # Apply spatial crop using stored dimensions
                cropped = frame[y:y+h, x:x+w]

                # Compare with previous frame
                if prev_frame is not None:
                    diff = cv2.absdiff(cropped, prev_frame)
                    mean_diff = np.mean(diff)
                    
                    if mean_diff > threshold:
                        # Save frame
                        filename = os.path.join(output_folder, f"frame_{saved_count:04d}.png")
                        cv2.imwrite(filename, cropped)
                        saved_count += 1

                prev_frame = cropped.copy()
                frame_count += 1

                # Update progress
                if frame_count % 10 == 0:
                    self.slider.setValue(self.start_frame + frame_count)
                    QApplication.processEvents()

            success_message = f"Saved {saved_count} frames" + (
                " (including color base)" if self.base_color_check.isChecked() else ""
            )
            QMessageBox.information(self, "Success", success_message)
            
        except Exception as e:
            QMessageBox.critical(self, "Error", f"Conversion failed: {str(e)}")
            
        finally:
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.current_frame)  # Restore playback position
            self.show_frame(self.current_frame)
        
if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = VideoConverter()
    window.show()
    sys.exit(app.exec_())
